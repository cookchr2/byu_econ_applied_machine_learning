{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello, and welcome to the Titanic Homework!  \n",
    "\n",
    "Christopher Cook  Machine Learning\n",
    "\n",
    "Let's get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import pandas and SKLearn stuff\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the data and take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open data\n",
    "train = pd.read_csv('C:/users/Christopher Cook/Downloads/kaggle/trainti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we can split up the cabin variable to get more information. The deck is the first letter and the room number is after it. Even numbers were on the right side of the ship so that might help predict as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can use the cabin number to get a better estimate of survival (for those who have it) Even numbers are on the right side \n",
    "#which is the side that was hit. We can also learn which deck they were on.\n",
    "train['deck'] = train['Cabin'].astype(str).str[0]\n",
    "train['even'] = train['Cabin'].str.endswith('0') + train['Cabin'].str.endswith('2') + train['Cabin'].str.endswith('4') \\\n",
    "                + train['Cabin'].str.endswith('6') + train['Cabin'].str.endswith('8')\n",
    "train['number'] = train['Cabin'].astype(str).str[1:]\n",
    "train['number'] = pd.to_numeric(train['number'],errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! I considered looking into the ticked number, but I don't think it's worth our time (as is the person's age). I don't think they would hold any predictive value. So, let's go and get rid of Nans and make dummies for class sex deck and embarkment place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's fill in the nans, and make dummies. Since we're using a forest we don't have to be too careful about what values we \n",
    "train = train.fillna(value={'Pclass' : 0, 'Name' : \"UKN\", 'Sex' : \"U\", 'Age' : -1, 'SibSp' : -1, 'Parch' : -1, 'Fare' : -1, \\\n",
    "                    'Embarked' : \"Unk\", 'even' : -1, 'number' : -1})\n",
    "rdy_train = pd.get_dummies(train[['Pclass','Sex','Embarked','deck']])\n",
    "for name in ['Survived','Age','SibSp','Parch','Fare']:\n",
    "    rdy_train[name] = train[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek to make sure everything looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_Unk</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>...</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>deck_n</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "0       3           0         1           0           0           1   \n",
       "1       1           1         0           1           0           0   \n",
       "2       3           1         0           0           0           1   \n",
       "3       1           1         0           0           0           1   \n",
       "4       3           0         1           0           0           1   \n",
       "\n",
       "   Embarked_Unk  deck_A  deck_B  deck_C   ...     deck_E  deck_F  deck_G  \\\n",
       "0             0       0       0       0   ...          0       0       0   \n",
       "1             0       0       0       1   ...          0       0       0   \n",
       "2             0       0       0       0   ...          0       0       0   \n",
       "3             0       0       0       1   ...          0       0       0   \n",
       "4             0       0       0       0   ...          0       0       0   \n",
       "\n",
       "   deck_T  deck_n  Survived   Age  SibSp  Parch     Fare  \n",
       "0       0       1         0  22.0      1      0   7.2500  \n",
       "1       0       0         1  38.0      1      0  71.2833  \n",
       "2       0       1         1  26.0      0      0   7.9250  \n",
       "3       0       0         1  35.0      1      0  53.1000  \n",
       "4       0       1         0  35.0      0      0   8.0500  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Sex_female',\n",
       " 'Sex_male',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S',\n",
       " 'Embarked_Unk',\n",
       " 'deck_A',\n",
       " 'deck_B',\n",
       " 'deck_C',\n",
       " 'deck_D',\n",
       " 'deck_E',\n",
       " 'deck_F',\n",
       " 'deck_G',\n",
       " 'deck_T',\n",
       " 'deck_n',\n",
       " 'Survived',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rdy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup! Looks great. Let's start training! We're going to start with OLS to get a baseline. (I know that if I were really interested in OLS I'd have made the data differently, but that doesn't have to stop us!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OK Let's split this into X and y and get started!\n",
    "X = rdy_train.drop(['Survived'], axis=1)\n",
    "y = rdy_train['Survived']\n",
    "#Though we will use the X and y later to train the submission model, we need a validation set\n",
    "Xtrain, Xtest, Ytrain, Ytest = model_selection.train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38802291217349999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First we're going to run OLS to get a basline for our data.\n",
    "ols = linear_model.LinearRegression(normalize=True)\n",
    "ols.fit(Xtrain,Ytrain)\n",
    "ols.score(Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is a pretty horrible R^2. Let's get into some forests! We're going to do Random Forest first, and then an Adaboosted forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79329608938547491"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OK let's do a random forest!\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [2,5,10], 'max_features' : [None, 'auto'] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "gsf.score(Xtest,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'auto', 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.845505617978\n"
     ]
    }
   ],
   "source": [
    "#Great! let's look at what hyperparameters we used\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there's some pretty bad overfitting going on. In the following cells I do some extensive hyperparameter tuning, until I find the best one is a max_depth of 4 and max_features of 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'max_features': 0.5, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.816011235955\n",
      "0.804469273743\n"
     ]
    }
   ],
   "source": [
    "#OK so we're painfully overfitting. Max depth will have to go down, and num_features too.\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [2,3], 'max_features' : [0.5,0.2] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'max_features': 0.5, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.816011235955\n",
      "0.804469273743\n"
     ]
    }
   ],
   "source": [
    "#Well, though our variance decreased, our out of sample prediction is the same: bad. Let's try some more tuning.\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [3,5], 'max_features' : [0.5,0.7] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'max_features': 1.0, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.818820224719\n",
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "#More tuning\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [3], 'max_features' : [1.0] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 0.5, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.955056179775\n",
      "0.837988826816\n"
     ]
    }
   ],
   "source": [
    "#More tuning\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [10], 'max_features' : [0.5] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 1.0, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.869382022472\n",
      "0.821229050279\n"
     ]
    }
   ],
   "source": [
    "#More tuning\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [5], 'max_features' : [1.0] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 1.0, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.837078651685\n",
      "0.810055865922\n"
     ]
    }
   ],
   "source": [
    "#More tuning\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [4], 'max_features' : [1.0] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 0.7, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.834269662921\n",
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "#More tuning\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [4], 'max_features' : [0.7] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 0.7, 'n_estimators': 1000, 'n_jobs': -1}\n",
      "0.89606741573\n",
      "0.826815642458\n"
     ]
    }
   ],
   "source": [
    "#More tuning\n",
    "gsf = model_selection.GridSearchCV(rf,{'n_estimators' : [1000], 'n_jobs' : [-1], \\\n",
    "                                       'max_depth' : [5,6], 'max_features' : [0.7] }, cv=7)\n",
    "gsf.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsf.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsf.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsf.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852974186308\n"
     ]
    }
   ],
   "source": [
    "#So I think our best bet here is a depth of 4 and all the features. Let's train our model on all our data\n",
    "rff = ensemble.RandomForestClassifier(n_estimators = 1000, max_depth = 4, max_features = 1.0)\n",
    "rff.fit(X,y)\n",
    "#Within sample accuracy\n",
    "print(rff.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we do the Adaboosted tree. I didn't get as good results as the Random forest, and I found that the validation set prediction tops out at the default parameters 1 and 50. I have to use 7 fold validation because the data is so small, we need as much data as we can to train on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.5, 'n_estimators': 50}\n",
      "0.825842696629\n",
      "0.782122905028\n"
     ]
    }
   ],
   "source": [
    "#OK now, Let's try it on a boosted tree\n",
    "ab = ensemble.AdaBoostClassifier()\n",
    "gsa = model_selection.GridSearchCV(ab,{'n_estimators' : [50], \\\n",
    "                                       'learning_rate' : [0.5,1.0,2.0]}, cv=7)\n",
    "gsa.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsa.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsa.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsa.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.0, 'n_estimators': 75}\n",
      "0.838483146067\n",
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "#Good, no crazy overfitting. Let's dig some more through the parameters:\n",
    "gsa = model_selection.GridSearchCV(ab,{'n_estimators' : [75], \\\n",
    "                                       'learning_rate' : [1.0]}, cv=7)\n",
    "gsa.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsa.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsa.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsa.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.75, 'n_estimators': 75}\n",
      "0.825842696629\n",
      "0.798882681564\n"
     ]
    }
   ],
   "source": [
    "#more fitting\n",
    "gsa = model_selection.GridSearchCV(ab,{'n_estimators' : [75], \\\n",
    "                                       'learning_rate' : [0.75]}, cv=7)\n",
    "gsa.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsa.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsa.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsa.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.0, 'n_estimators': 25}\n",
      "0.827247191011\n",
      "0.821229050279\n"
     ]
    }
   ],
   "source": [
    "#more fitting\n",
    "gsa = model_selection.GridSearchCV(ab,{'n_estimators' : [25], \\\n",
    "                                       'learning_rate' : [1.0]}, cv=7)\n",
    "gsa.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsa.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsa.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsa.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.5, 'n_estimators': 25}\n",
      "0.821629213483\n",
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "#more fitting\n",
    "gsa = model_selection.GridSearchCV(ab,{'n_estimators' : [25], \\\n",
    "                                       'learning_rate' : [1.5]}, cv=7)\n",
    "gsa.fit(Xtrain,Ytrain)\n",
    "#best hyperparameters\n",
    "print(gsa.best_params_)\n",
    "#Within sample accuracy\n",
    "print(gsa.score(Xtrain,Ytrain))\n",
    "#out of sample accuracy\n",
    "print(gsa.score(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've estimated our models, we're going to prep our testing data and submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OK this is going nowhere. It's easy to see that we're sitting on a max on the default values.\n",
    "#Therefore, our best estimator was random forest. Let's get some predicted values!\n",
    "test = pd.read_csv('testti.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm going to follow what I did before as close as I can\n",
    "#making deck, even and number\n",
    "test['deck'] = test['Cabin'].astype(str).str[0]\n",
    "test['even'] = test['Cabin'].str.endswith('0') + test['Cabin'].str.endswith('2') + test['Cabin'].str.endswith('4') \\\n",
    "                + test['Cabin'].str.endswith('6') + test['Cabin'].str.endswith('8')\n",
    "test['number'] = test['Cabin'].astype(str).str[1:]\n",
    "test['number'] = pd.to_numeric(test['number'],errors='coerce')\n",
    "#filling in nas\n",
    "test = test.fillna(value={'Pclass' : 0, 'Name' : \"UKN\", 'Sex' : \"U\", 'Age' : -1, 'SibSp' : -1, 'Parch' : -1, 'Fare' : -1, \\\n",
    "                    'Embarked' : \"Unk\", 'even' : -1, 'number' : -1})\n",
    "#filling misc nas\n",
    "test = test.fillna(-1)\n",
    "#making dummies\n",
    "rdy_test = pd.get_dummies(test[['Pclass','Sex','Embarked','deck']])\n",
    "#adding numericals values\n",
    "for name in ['Age','SibSp','Parch','Fare']:\n",
    "    rdy_test[name] = test[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make the columns match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Sex_female',\n",
       " 'Sex_male',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S',\n",
       " 'deck_-',\n",
       " 'deck_A',\n",
       " 'deck_B',\n",
       " 'deck_C',\n",
       " 'deck_D',\n",
       " 'deck_E',\n",
       " 'deck_F',\n",
       " 'deck_G',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rdy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Sex_female',\n",
       " 'Sex_male',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S',\n",
       " 'Embarked_Unk',\n",
       " 'deck_A',\n",
       " 'deck_B',\n",
       " 'deck_C',\n",
       " 'deck_D',\n",
       " 'deck_E',\n",
       " 'deck_F',\n",
       " 'deck_G',\n",
       " 'deck_T',\n",
       " 'deck_n',\n",
       " 'Survived',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rdy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making the two match:\n",
    "rdy_test['deck_n'] = rdy_test['deck_-']\n",
    "rdy_test['Embarked_Unk'] = 0\n",
    "rdy_test['deck_T'] = 0\n",
    "rdy_test = rdy_test.drop(['deck_-'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you go! We made our prediction! It was about middle of the pack on Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Survived'] = rff.predict(rdy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['PassengerId','Survived']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For Curiosity's sake, I want to see the features importance for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15e797f2630>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAE9CAYAAADnIbI9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e797f2e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#Get the Feature importantces for the data\n",
    "%matplotlib inline\n",
    "feature_imp = sorted(list(zip(list(X), rff.feature_importances_)), key=lambda x: x[1], reverse=True)\n",
    "ls = pd.Series([x[1] for x in feature_imp], index=[x[0] for x in feature_imp])\n",
    "ls[0:22].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph agrees with my intuition. (It's also why sampling features didn't work). Sex is clearly a huge predictor, and I'd guess that a tree without it would be pretty lost. Age and proxies for wealth are next, which makes sense. (deck_n means missing, which means they were probably living near the bottom of the ship)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, I hope you enjoyed this as much as I did! Have a great one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
